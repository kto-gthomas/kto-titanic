{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c35abf",
   "metadata": {},
   "source": [
    "# Create s3 client and download data from minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf1a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/kto-titanic/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "MLFLOW_S3_ENDPOINT_URL = \"https://minio-api-$$$$-dev.apps.$$$.openshiftapps.com\" # <--- mettez ici votre endpoint minio\n",
    "AWS_ACCESS_KEY_ID = \"$$$\"\n",
    "AWS_SECRET_ACCESS_KEY = \"$$$\"\n",
    "\n",
    "def load_data(path: str) -> str:\n",
    "  local_path = Path(\"./\", \"data.csv\")\n",
    "  logging.warning(f\"to path : {local_path}\")\n",
    "\n",
    "  s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=MLFLOW_S3_ENDPOINT_URL,\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "  )\n",
    "\n",
    "  s3_client.download_file(\"kto-titanic\", path, local_path)\n",
    "  df = pd.read_csv(local_path)\n",
    "\n",
    "  profile = ProfileReport(df, title=f\"Profiling Report - {local_path.stem}\")\n",
    "  profile_path = Path(\"./\", \"profile.html\")\n",
    "  profile.to_file(profile_path)\n",
    "\n",
    "  return local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88503b56",
   "metadata": {},
   "source": [
    "# Random split train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8d1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "FEATURES = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "TARGET = \"Survived\"\n",
    "\n",
    "\n",
    "def split_train_test(data_path: str) -> tuple[str, str, str, str]:\n",
    "  logging.warning(f\"split on {data_path}\")\n",
    "\n",
    "  df = pd.read_csv(data_path, index_col=False)\n",
    "\n",
    "  y = df[TARGET]\n",
    "  x = df[FEATURES]\n",
    "  x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "  datasets = [\n",
    "    (x_train, \"xtrain\", \"xtrain.csv\"),\n",
    "    (x_test, \"xtest\", \"xtest.csv\"),\n",
    "    (y_train, \"ytrain\", \"ytrain.csv\"),\n",
    "    (y_test, \"ytest\", \"ytest.csv\"),\n",
    "  ]\n",
    "\n",
    "  artifact_paths = []\n",
    "  for data, artifact_path, filename in datasets:\n",
    "    file_path = Path(\"./\", filename)\n",
    "    data.to_csv(file_path, index=False)\n",
    "    artifact_paths.append(file_path)\n",
    "\n",
    "  return tuple(artifact_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2565764",
   "metadata": {},
   "source": [
    "# Train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541c3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ARTIFACT_PATH = \"model_trained\"\n",
    "\n",
    "\n",
    "def train(x_train_path: str, y_train_path: str, n_estimators: int, max_depth: int, random_state: int) -> str:\n",
    "  logging.warning(f\"train {x_train_path} {y_train_path}\")\n",
    "  x_train = pd.read_csv(x_train_path, index_col=False)\n",
    "  y_train = pd.read_csv(y_train_path, index_col=False)\n",
    "\n",
    "  x_train = pd.get_dummies(x_train)\n",
    "\n",
    "  model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "  model.fit(x_train, y_train)\n",
    "\n",
    "  model_filename = \"model.joblib\"\n",
    "\n",
    "  model_path = Path(\"./\", model_filename)\n",
    "  joblib.dump(model, model_path)\n",
    "\n",
    "\n",
    "  return model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e8295",
   "metadata": {},
   "source": [
    "# Evaluate ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e303cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error\n",
    "\n",
    "def validate(model_path: str, x_test_path: str, y_test_path: str) -> None:\n",
    "  logging.warning(f\"validate {model_path}\")\n",
    "  model = joblib.load(model_path)\n",
    "\n",
    "  x_test = pd.read_csv(x_test_path, index_col=False)\n",
    "  y_test = pd.read_csv(y_test_path, index_col=False)\n",
    "\n",
    "  x_test = pd.get_dummies(x_test)\n",
    "\n",
    "  if y_test.shape[1] == 1:\n",
    "    y_test = y_test.iloc[:, 0]\n",
    "\n",
    "  y_pred = model.predict(x_test)\n",
    "\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  r2 = r2_score(y_test, y_pred)\n",
    "  medae = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "  feature_names = x_test.columns.tolist()\n",
    "\n",
    "  if hasattr(model, \"feature_importances_\"):\n",
    "    importances = model.feature_importances_\n",
    "    feature_importance = {\n",
    "      name: float(importance) for name, importance in zip(feature_names, importances, strict=False)\n",
    "    }\n",
    "  elif hasattr(model, \"coef_\"):\n",
    "    coefs = model.coef_\n",
    "    if hasattr(coefs, \"shape\") and len(coefs.shape) > 1:\n",
    "      coefs = coefs[0]\n",
    "    feature_importance = {name: float(coef) for name, coef in zip(feature_names, coefs, strict=False)}\n",
    "  else:\n",
    "    feature_importance = {name: 0.0 for name in feature_names}\n",
    "    logging.warning(\"Model does not have feature importance attributes\")\n",
    "\n",
    "  logging.warning(f\"mse : {mse}\")\n",
    "  logging.warning(f\"mae : {mae}\")\n",
    "  logging.warning(f\"r2 : {r2}\")\n",
    "  logging.warning(f\"medae : {medae}\")\n",
    "  logging.warning(f\"feature importance : {feature_importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be6a08e",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc64b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:to path : data.csv\n",
      "100%|██████████| 12/12 [00:00<00:00, 105.76it/s]<00:00, 23.85it/s, Describe variable: Embarked]\n",
      "Summarize dataset: 100%|██████████| 47/47 [00:03<00:00, 13.75it/s, Completed]                       \n",
      "Generate report structure: 100%|██████████| 1/1 [00:04<00:00,  4.72s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 148.67it/s]\n",
      "WARNING:root:split on data.csv\n",
      "WARNING:root:train xtrain.csv ytrain.csv\n",
      "/projects/kto-titanic/.venv/lib/python3.13/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "WARNING:root:validate model.joblib\n",
      "WARNING:root:mse : 0.13994910941475827\n",
      "WARNING:root:mae : 0.13994910941475827\n",
      "WARNING:root:r2 : 0.40546264715590286\n",
      "WARNING:root:medae : 0.0\n",
      "WARNING:root:feature importance : {'Pclass': 0.10482572405228158, 'SibSp': 0.06165378878974374, 'Parch': 0.05724675535861529, 'Sex_female': 0.4115915114843067, 'Sex_male': 0.36468222031505265}\n"
     ]
    }
   ],
   "source": [
    "local_path = load_data(\"all_titanic.csv\")\n",
    "xtrain_path, xtest_path, ytrain_path, ytest_path = split_train_test(local_path)\n",
    "model_path = train(xtrain_path, ytrain_path, 100, 10, 42)\n",
    "validate(model_path, xtest_path, ytest_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
